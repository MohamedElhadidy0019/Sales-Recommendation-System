{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE: 44.1370\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "44.13696102551999"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from surprise import Dataset, Reader, SVD\n",
    "from surprise.model_selection import train_test_split\n",
    "from surprise import accuracy\n",
    "from typing import List\n",
    "\n",
    "def preprocess(dataset_name: str = 'Dataset.csv') -> pd.DataFrame: \n",
    "    # Load the dataset (excluding Description and InvoiceDate columns)\n",
    "    df = pd.read_csv(dataset_name, usecols=['CustomerID', 'StockCode', 'Quantity'])\n",
    "\n",
    "    # Preprocess the data (drop NaN rows and convert to integer)\n",
    "    df.dropna(subset=['CustomerID', 'StockCode', 'Quantity'], inplace=True)\n",
    "    # drop StockCode with non-numeric values\n",
    "    df = df[df['StockCode'].str.isnumeric()]\n",
    "\n",
    "    df = df.astype({'CustomerID': int, 'StockCode': int, 'Quantity': int})\n",
    "    return df\n",
    "\n",
    "\n",
    "def split_df(df: pd.DataFrame, test_size: float = 0.2) -> (pd.DataFrame, pd.DataFrame):\n",
    "    users = df['CustomerID'].unique()\n",
    "    test_len = test_size*(len(users))\n",
    "    test_customers = users[:int(test_len)]\n",
    "    train_customers = users[int(test_len):]\n",
    "\n",
    "    # make the train df have unique customers from test df to avoid data leakage\n",
    "    df_train = df[df['CustomerID'].isin(train_customers)]\n",
    "    \n",
    "    df_test = df[df['CustomerID'].isin(test_customers)]\n",
    "    \n",
    "    # Create  Surprise Dataset\n",
    "    reader = Reader(rating_scale=(1, 5))\n",
    "    trainset = Dataset.load_from_df(df_train[['CustomerID', 'StockCode', 'Quantity']], reader)\n",
    "    testset = Dataset.load_from_df(df_test[['CustomerID', 'StockCode', 'Quantity']], reader)\n",
    "\n",
    "    # the folowing 2 lines were just work arounds in order to make itterable objects suitable for the SVD fit method\n",
    "    trainset, _ = train_test_split(trainset, test_size=0.01, random_state=42)\n",
    "    _, testset = train_test_split(testset, test_size=0.09, random_state=42)\n",
    "\n",
    "    return trainset, testset\n",
    "\n",
    "# Function to get item recommendations for a given user\n",
    "def get_item_recommendations(user_id:int, dataset_path:str, model, num_recommendations=5)->List[int]:\n",
    "    # Load the dataset\n",
    "    df =preprocess(dataset_path)\n",
    "    items_already_purchased = df[df['CustomerID'] == user_id]['StockCode'].tolist()\n",
    "    \n",
    "    # Get all item IDs\n",
    "    item_ids = df['StockCode'].unique()\n",
    "    \n",
    "    # Remove items already purchased\n",
    "    items_to_predict = [item_id for item_id in item_ids if item_id not in items_already_purchased]\n",
    "    \n",
    "    # Predict ratings for items\n",
    "    predictions = [model.predict(user_id, item_id) for item_id in items_to_predict]\n",
    "    \n",
    "    # Sort predictions by predicted rating\n",
    "    predictions.sort(key=lambda x: x.est, reverse=True)\n",
    "    \n",
    "    # Get top N recommended items\n",
    "    top_recommendations = [prediction.iid for prediction in predictions[:num_recommendations]]\n",
    "    return top_recommendations\n",
    "\n",
    "df = preprocess('Dataset.csv')\n",
    "trainset, testset = split_df(df)\n",
    "\n",
    "# Train the model\n",
    "model = SVD(n_factors=50, random_state=42)\n",
    "model.fit(trainset)\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.test(testset)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy.rmse(predictions)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE:  11.9272\n",
      "MAE: 11.927197700980031\n",
      "Precision: 0.6513153046938325\n",
      "Recall: 1.0\n",
      "F1-Score: 0.7888442659526997\n"
     ]
    }
   ],
   "source": [
    "from surprise.accuracy import mae\n",
    "from surprise.model_selection import cross_validate\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "# Calculate MAE using Surprise's built-in function\n",
    "mae_score = mae(predictions)\n",
    "\n",
    "# Convert predictions to binary recommendations (1 for predicted ratings >= 3, 0 otherwise)\n",
    "\n",
    "# the est is the estimate of the matrix that came from the SVD\n",
    "binary_predictions = [1 if prediction.est >= 3 else 0 for prediction in predictions]\n",
    "# the r_ui is the actual rating\n",
    "binary_actuals = [1 if prediction.r_ui >= 3 else 0 for prediction in predictions]\n",
    "\n",
    "# Calculate Precision, Recall, and F1-Score using scikit-learn\n",
    "precision = precision_score(binary_actuals, binary_predictions)\n",
    "recall = recall_score(binary_actuals, binary_predictions)\n",
    "f1 = f1_score(binary_actuals, binary_predictions)\n",
    "\n",
    "print(\"MAE:\", mae_score)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1-Score:\", f1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item recommendations for User ID: 17850\n",
      "[84879, 22745, 22748, 22749, 22310]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Get item recommendations for a specific user\n",
    "user_id = 17850  # Replace with a valid CustomerID\n",
    "recommendations = get_item_recommendations(user_id,'Dataset.csv',model)\n",
    "print(\"Item recommendations for User ID:\", user_id)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from surprise import dump\n",
    "\n",
    "# Assuming you have trained the model as 'model'\n",
    "model_filename = 'trained_model.pkl'  # Specify the desired file name for the model\n",
    "\n",
    "# Save the model to the current working directory\n",
    "dump.dump(model_filename, algo=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[84879, 22745, 22748, 22749, 22310]\n"
     ]
    }
   ],
   "source": [
    "loaded_model = dump.load('trained_model.pkl')[1]\n",
    "recommendations = get_item_recommendations(user_id,'Dataset.csv',loaded_model)\n",
    "print(recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rmd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.17"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
